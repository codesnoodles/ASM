# 信息论
----
## 概论
----
### 信息的概念和分类
* 信息的定义:信息是对事物运动状态和变化方式的表征,存在于任何事物中,可以被人获取并利用
* 信息分类:按照性质分为 语法信息语义信息和语用信息
###　信息论的起源和发展
* 理论基础技术条件
* 诞生和发展
###　信息论研究内容
* 通信系统模型
  ```mermaid
  graph LR
  1[信源]-->2[信源编码]
  2-->3[加密]
  3-->4[信道编码]
  ```
  ```mermaid
  graph LR
  1[信道译码]-->2[解密]
  2-->3[信源译码]
  3-->4[信宿]
  ```
* 信息论基础: 无失真信源编码,信道编码,限失真信源编码
* 一般信息论:从信源到信宿的全过程重点是编码.在传输前后对消息进行适当的编码和译码就可以再有干扰的情况下最佳的传送消息
## 离散信源熵
----
### 基本概念
* 从随机变量出发研究信息论
### 离散信源熵的基本概念和性质
* 简单理解信源随机发送集合内的信息每个信息发送对应一个概率
* 多个信源可以联合起来
* 根据概率可以计算信息量,重要公式:全概率公式,贝叶斯公式
* 自信息量:$I(a_i)=-log_2p(a_i)$
* 信源熵:$H(X)=E[I(a_i)]=-\sum_{i=1}^np(a_i)log_2p(a_i)$
* 信源熵的性质:非负性,对称性,最大离散熵定理$H(X)\leqslant log_2n$,拓展性,确定性,可加性,极值性,上凸性
### 多符号离散平稳信源熵
* 无论任何时刻信源发送信息的概率是相同的
* 离散无记忆说明信源发送与前发送信息无关
* 离散有记忆发出的各个符号之间由统计关联
##　无失真离散信源编码
----
### 基本概念
* 信源编码目的:降低代码冗余度,实现有效性提高
* 信道编码提升代码冗余度实现可靠性提高
* 无失真信源编码定理是离散信源或数字信号编码的基础
* 限失真信源编码是连续信源或模拟信号编码的基础
### 离散无失真信源编码定理
* 定长编码定理:${{K}\over{L}}log_2 m\geqslant H(x)+\epsilon$
* 信息率略大于单符号熵时可以做到无失真译码,条件是$L\geqslant {{\sigma^2[I(a_i)]}\over{\epsilon^2\delta}}$
* 变长编码定理,为了解决等长编码过长的问题.效率为$\eta={{H(X)}\over{R}}>{{H(X)}\over{H(X)+{{log_2m}\over{L}}}}$
* 码字唯一可译条件对于编码结构有要求
### 香农编码
### 费诺编码
### 赫夫曼编码
* 码字可分离,即时码
## 离散信道容量
----
### 互信息量和平均信息量
* 互信息量:$互信息量=log_2{{后验概率}\over{先验概率}}$
* 平均互信息量的意义:信道疑义度,损失熵,也就是信道中损失的信息
### 单符号离散信道的信道容量
* 信道的信息传输率:$R=I(X;Y)$
* 信道容量是最大的信息传输速率:$C=max_{p(a_i)}I(X;Y)$
### 多符号离散信道的信道容量
## 纠错编码
----
### 基本概念
* 前向反馈,反馈重传,混合纠错
* 纠错编码分类
## 连续信源熵
----
### 连续信源熵
* 特殊的连续信源熵:均匀分布,高斯分布,指数分布
* 连续信源熵的的性质和定理: 可为负值,可加性,平均互信息量的非负性,最大连续熵定理.
### 熵功率
* 概率密度函数服从高斯分布时,达到最大熵值
### 连续信道的信道容量
* 信道条件熵也就是噪声熵.
## 信息率失真函数
----
### 基本概念
* 信息率小于信道容量则可以无失真传输,信息率必须大于信源熵H(X),在允许一定失真度的情况下,心愿输出的信息率可以压缩到R(D)值
* 信息率是真理论是量化,数模转换,频带压缩数据压缩的理论基础
* 失真函数和平均失真度,平均失真度时总体上对整个系统失真情况的描述,是信源统计特性信道统计特性以及认为规定的失真度的函数
* 信息率是真函数也就是最小的平均互信息量$R_N(D)=min_{p(b_j/a_i)\in P_D}I(X;Y)$
* 平均互信息量即使心愿概率分布的上凸函数,也是信道条件转移概率的下凹函数.
### 信道容量和信息率失真函数的比较
* 信道容量实在固定信源的情况下,求平均互信息量极大值的问题.
* 信息率是真函数实在实验信道中寻找平均互信息量条件极小值确定下界的问题.$R(D)=min_{p(b_j/a_i)\in P_D}I(X;Y)$
## 限失真信源编码
----
### 基本概念
* 离散信源可以进行一对一编码.连续信源取之无穷多必然产生失真,因此考虑主要信号的编码忽略一些次要的信号,既满足保真度原则又保证通信的质量
* 信源编码定理译码平均失真度大于允许失真度
* 香农信息论三个基本概念--信源熵,信道容量,信息率失真函数,对应三个定理:无失真信源编码定理,信道编码定理,限失真信源编码定理