# 信息论
----
## 概论
----
### 信息的概念和分类
* 信息的定义:信息是对事物运动状态和变化方式的表征,存在于任何事物中,可以被人获取并利用
* 信息分类:按照性质分为 语法信息语义信息和语用信息
###　信息论的起源和发展
* 理论基础技术条件
* 诞生和发展
###　信息论研究内容
* 通信系统模型
  ```mermaid
  graph LR
  1[信源]-->2[信源编码]
  2-->3[加密]
  3-->4[信道编码]
  ```
  ```mermaid
  graph LR
  1[信道译码]-->2[解密]
  2-->3[信源译码]
  3-->4[信宿]
  ```
* 信息论基础: 无失真信源编码,信道编码,限失真信源编码
* 一般信息论:从信源到信宿的全过程重点是编码.在传输前后对消息进行适当的编码和译码就可以再有干扰的情况下最佳的传送消息
## 离散信源熵
----
### 基本概念
* 从随机变量出发研究信息论
### 离散信源熵的基本概念和性质
* 简单理解信源随机发送集合内的信息每个信息发送对应一个概率
* 多个信源可以联合起来
* 根据概率可以计算信息量,重要公式:全概率公式,贝叶斯公式
* 自信息量:$I(a_i)=-log_2p(a_i)$
* 信源熵:$H(X)=E[I(a_i)]=-\sum_{i=1}^np(a_i)log_2p(a_i)$
* 信源熵的性质:非负性,对称性,最大离散熵定理$H(X)\leqslant log_2n$,拓展性,确定性,可加性,极值性,上凸性
### 多符号离散平稳信源熵
* 无论任何时刻信源发送信息的概率是相同的
* 离散无记忆说明信源发送与前发送信息无关
* 离散有记忆发出的各个符号之间由统计关联